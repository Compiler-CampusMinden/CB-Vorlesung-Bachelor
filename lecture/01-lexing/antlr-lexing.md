# Lexer mit ANTLR generieren

> [!IMPORTANT]
>
> <details open>
>
> <summary><strong>üéØ TL;DR</strong></summary>
>
> ANTLR ist ein Parser-Generator, der aus einer Grammatik einen Parser
> in verschiedenen Zielsprachen (Java, Python, C++, ‚Ä¶) generieren kann.
>
> In der ANTLR-Grammatik werden die Parser-Regeln klein geschrieben, die
> Lexer-Regeln werden mit **Gro√übuchstaben** geschrieben. Jede
> Lexer-Regel liefert ein Token zur√ºck, dabei ist der Tokenname die
> linke Seite der Regel. Wie bei Flex gewinnt der l√§ngste Match, und bei
> Gleichstand (mehrere l√§ngste Regeln matchen) gewinnt die zuerst
> definierte Regel.
>
> Die Lexer-Regeln k√∂nnen mit Aktionen annotiert werden, die beim
> Matchen der jeweiligen Regel abgearbeitet werden. Diese Aktionen
> m√ºssen in der Zielprogrammiersprache formuliert werden, da sie in die
> generierte Lexerklasse in die jeweiligen Methoden eingebettet werden.
> </details>

> [!TIP]
>
> <details open>
>
> <summary><strong>üé¶ Videos</strong></summary>
>
> - [VL Lexer mit ANTLR](https://youtu.be/dvx8RLirfp0)
> - [Demo ANTLR Basics](https://youtu.be/pbjGThqVLkU)
> - [Demo Verhalten Lexer-Regeln](https://youtu.be/vnJIm6S-898)
> - [Demo Lexer-Regeln mit Aktionen](https://youtu.be/bNpgqctiQM8)
>
> </details>

## Lexer: Erzeugen eines Token-Stroms aus einem Zeichenstrom

Aus dem Eingabe(-quell-)text

``` c
/* demo */
a= [5  , 6]     ;
```

erstellt der Lexer (oder auch Scanner genannt) eine Sequenz von Token:

    <ID, "a"> <ASSIGN> <LBRACK> <NUM, 5> <COMMA> <NUM, 6> <RBRACK> <SEMICOL>

- Input: Zeichenstrom (Eingabedatei o.√§.)
- Verarbeitung: Finden sinnvoller Sequenzen im Zeichenstrom (‚ÄúLexeme‚Äù),
  Einteilung in Kategorien und Erzeugen von Token (Paare: Typ/Name,
  Wert)
- Ausgabe: Tokenstrom

Normalerweise werden f√ºr sp√§tere Phasen unwichtige Elemente wie
White-Space oder Kommentare entfernt.

Durch diese Vorverarbeitung wird eine h√∂here Abstraktionsstufe erreicht
und es k√∂nnen erste grobe Fehler gefunden werden. Dadurch kann der
Parser auf einer abstrakteren Stufe arbeiten und muss nicht mehr den
gesamten urspr√ºnglichen Zeichenstrom verarbeiten.

*Anmerkung*: In dieser Phase steht die Geschwindigkeit stark im
Vordergrund: Der Lexer ‚Äúsieht‚Äù *alle* Zeichen im Input. Deshalb findet
man h√§ufig von Hand kodierte Lexer, obwohl die Erstellung der Lexer auch
durch Generatoren erledigt werden k√∂nnte ‚Ä¶

*Anmerkung*: Die Token sind die Terminalsymbole in den Parserregeln
(Grammatik).

## Definition wichtiger Begriffe

- **Token**: Tupel (Tokenname, optional: Wert)

  Der Tokenname ist ein abstraktes Symbol, welches eine lexikalische
  Einheit repr√§sentiert (Kategorie). Die Tokennamen sind die
  Eingabesymbole f√ºr den Parser.

  Token werden i.d.R. einfach √ºber ihren Namen referenziert. Token
  werden h√§ufig zur Unterscheidung von anderen Symbolen in der Grammatik
  in Fettschrift oder mit gro√üen Anfangsbuchstaben geschrieben.

  Ein Token kann einen Wert haben, etwa eine Zahl oder einen Bezeichner,
  der auf das zum Token geh√∂rende Pattern gematcht hatte (also das
  Lexem). Wenn der Wert des Tokens eindeutig √ºber den Namen bestimmt ist
  (im Beispiel oben beim Komma oder den Klammern), dann wird h√§ufig auf
  den Wert verzichtet.

<!-- -->

- **Lexeme**: Sequenz von Zeichen im Eingabestrom, die auf ein
  Tokenpattern matcht und vom Lexer als Instanz dieses Tokens
  identifiziert wird.

<!-- -->

- **Pattern**: Beschreibung der Form eines Lexems

  Bei Schl√ºsselw√∂rtern oder Klammern etc. sind dies die Schl√ºsselw√∂rter
  oder Klammern selbst. Bei Zahlen oder Bezeichnern (Namen) werden
  i.d.R. regul√§re Ausdr√ºcke zur Beschreibung der Form des Lexems
  formuliert.

## Typische Muster f√ºr Erstellung von Token

1.  Schl√ºsselw√∂rter

    - Ein eigenes Token (RE/DFA) f√ºr jedes Schl√ºsselwort, oder
    - Erkennung als Name (`ID`) und nachtr√§glich Vergleich mit
      W√∂rterbuch sowie Korrektur des Tokentyps

    Wenn Schl√ºsselw√∂rter √ºber je ein eigenes Token abgebildet werden,
    ben√∂tigt man f√ºr jedes Schl√ºsselwort einen eigenen RE bzw. DFA. Die
    Erkennung als Bezeichner und das Nachschlagen in einem W√∂rterbuch
    (geeignete Hashtabelle) sowie die entsprechende nachtr√§gliche
    Korrektur des Tokentyps kann die Anzahl der Zust√§nde im Lexer
    signifikant reduzieren!

2.  Operatoren

    - Ein eigenes Token f√ºr jeden Operator, oder
    - Gemeinsames Token f√ºr jede Operatoren-Klasse

3.  Bezeichner: Ein gemeinsames Token f√ºr alle Namen

4.  Zahlen: Ein gemeinsames Token f√ºr alle numerischen Konstante (ggf.
    Integer und Float unterscheiden)

    F√ºr Zahlen f√ºhrt man oft ein Token ‚Äú`NUM`‚Äù ein. Als Attribut
    speichert man das Lexem i.d.R. als String. Alternativ kann man
    (zus√§tzlich) das Lexem in eine Zahl konvertieren und als
    (zus√§tzliches) Attribut speichern. Dies kann in sp√§teren Stufen viel
    Arbeit sparen.

5.  String-Literale: Ein gemeinsames Token

6.  Komma, Semikolon, Klammern, ‚Ä¶: Je ein eigenes Token

7.  Regeln f√ºr White-Space und Kommentare etc. ‚Ä¶

    Normalerweise ben√∂tigt man Kommentare und White-Spaces in den
    folgenden Stufen nicht und entfernt diese deshalb aus dem
    Eingabestrom. Dabei k√∂nnte man etwa White-Spaces in den Pattern der
    restlichen Token ber√ºcksichtigen, was die Pattern aber sehr komplex
    macht. Die Alternative sind zus√§tzliche Pattern, die auf die
    White-Space und anderen nicht ben√∂tigten Inhalt matchen und diesen
    ‚Äúger√§uschlos‚Äù entfernen. Mit diesen Pattern werden keine Token
    erzeugt, d.h. der Parser und die anderen Stufen bemerken nichts von
    diesem Inhalt.

    Gelegentlich ben√∂tigt man aber auch Informationen √ºber White-Spaces,
    beispielsweise in Python. Dann m√ºssen diese Token wie normale Token
    an den Parser weitergereicht werden.

Jedes Token hat i.d.R. ein Attribut, in dem das Lexem gespeichert wird.
Bei eindeutigen Token (etwa bei eigenen Token je Schl√ºsselwort oder bei
den Interpunktions-Token) kann man sich das Attribut auch sparen, da das
Lexem durch den Tokennamen eindeutig rekonstruierbar ist.

| Token | Beschreibung | Beispiel-Lexeme |
|:---|:---|:---|
| `if` | Zeichen `i` und `f` | `if` |
| `relop` | `<` oder `>` oder `<=` oder `>=` oder `==` oder `!=` | `<`, `<=` |
| `id` | Buchstabe, gefolgt von Buchstaben oder Ziffern | `pi`, `count`, `x3` |
| `num` | Numerische Konstante | `42`, `3.14159`, `0` |
| `literal` | Alle Zeichen au√üer `"`, in `"` eingeschlossen | `"core dumped"` |

*Anmerkung*: Wenn es mehrere matchende REs gibt, wird in der Regel das
l√§ngste Lexem bevorzugt. Wenn es mehrere gleich lange Alternativen gibt,
muss man mit Vorrangregeln bzgl. der Token arbeiten.

## ‚ÄúHello World‚Äù mit ANTLR (Lexer)

``` antlr
grammar Hello;

start       : 'hello' GREETING ;

GREETING    : [a-zA-Z]+ ;
WHITESPACE  : [ \t\n]+ -> skip ;
```

<p align="right"><a href="https://github.com/Compiler-CampusMinden/CB-Vorlesung-Bachelor/blob/master/lecture/01-lexing/src/Hello.g4">Konsole: Hello (Classpath, Aliase, grun, Main, Dateien, Ausgabe)</a></p>

### Hinweis zur Grammatik (Regeln)

- `start` ist eine Parser-Regel =\> Eine Parser-Regel pro Grammatik wird
  ben√∂tigt, damit man den generierten Parser am Ende auch starten kann ‚Ä¶
- Die anderen beiden Regeln (mit gro√üem Anfangsbuchstaben) aus der
  obigen Grammatik z√§hlen zum Lexer

### ANTLR einrichten

- Lokal f√ºr die Nutzung in der Konsole:

  - Es wird ein JDK ben√∂tigt. Installieren Sie am besten die aktuelle
    LTS-Version.
  - Aktuelle Version herunterladen:
    [antlr.org](https://www.antlr.org/download.html), f√ºr Java als
    Zielsprache: [‚ÄúComplete ANTLR 4.x Java binaries
    jar‚Äù](https://www.antlr.org/download/antlr-4.13.2-complete.jar)
  - CLASSPATH setzen:
    `export CLASSPATH=".:/<pathToJar>/antlr-4.13.2-complete.jar:$CLASSPATH"`
  - Aliase einrichten (`.bashrc`):
    - `alias antlr='java org.antlr.v4.Tool'`
    - `alias grun='java org.antlr.v4.gui.TestRig'`

- Alternativ f√ºr Java-Projekte mit Gradle (empfehlenswert):

      plugins {
          id 'java'
          id 'antlr'
      }

      repositories {
          mavenCentral()
      }

      dependencies {
          antlr 'org.antlr:antlr4:4.13.2'
      }

  Der Eintrag in `plugins` sorgt daf√ºr, dass Gradle beim Bauen des
  Java-Projekts die ANTLR-Grammatiken √ºbersetzt, der Eintrag in
  `dependencies` l√§dt automatisch das Jar-File f√ºr ANTLR herunter und
  bindet es entsprechend im CLASSPATH ein.

- Alternativ das [ANTLR tool
  (JAR)](https://www.antlr.org/download/antlr-4.13.2-complete.jar)
  manuell herunterladen und in der IDE als Library hinzuf√ºgen (bitte nur
  als Hilfsl√∂sung, der Weg √ºber das Build-Tool ist deutlich besser)

- Im Web ohne lokale Installation: [ANTLR Lab](http://lab.antlr.org/)
  (nur HTTP)

(vgl.
[github.com/antlr/antlr4/blob/master/doc/getting-started.md](https://github.com/antlr/antlr4/blob/master/doc/getting-started.md))

**Tip**: F√ºr IntelliJ gibt es ein sehr gutes
[ANTLR-Plugin](https://plugins.jetbrains.com/plugin/7358-antlr-v4).
Dieses erlaubt das interaktive Experimentieren mit ANTLR-Grammatiken,
ohne dass man ANTLR selbst installiert haben muss oder Code geschrieben
haben muss. F√ºr die Arbeit mit Grammatiken ist dieses Plugin unbedingt
empfehlenswert! (F√ºr das normale Arbeiten sollten Sie aber die
Gradle-Konfiguration nutzen!)

**Hinweis**: Im Beispiel-Projekt
[student-support-code-template](https://github.com/Compiler-CampusMinden/student-support-code-template)
finden Sie ein fertig eingerichtetes Java-Projekt mit Gradle und ANTLR.
Sie k√∂nnen dieses Projekt als Template nutzen und in Ihrer IDE
importieren, d.h. Sie brauchen nur ein installiertes JDK (Version 25 ist
die aktuelle LTS) und eine Java-IDE, der Rest (Gradle, ANTLR) kommt √ºber
die Einstellungen im Beispiel-Projekt. Durch die Gradle-Settings sollten
anschlie√üend alle n√∂tigen Einstellungen und Abh√§ngigkeiten automatisch
in der IDE korrekt gesetzt bzw. aufgel√∂st werden. Im `Main.main()`
finden Sie eine kurze Demo, wie man einen generierten Lexer/Parser mit
einbindet und aufruft. Grammatiken k√∂nnen unter `src/main/antlr/`
abgelegt werden, wo sie automatisch vom ANTLR-Gradle-Plugin beim
Build-Prozess (`./gradlew build`) gefunden und bearbeitet werden. Die
daraus generierten ANTLR-Lexer und -Parser werden im Build-Ordner
`build/generated-src/antlr/main/` abgelegt und stehen in der IDE damit
automatisch zur Verf√ºgung, ohne dass die generierten Dateien im
versionierten Source-Tree auftauchen und diesen ‚Äúverschmutzen‚Äù.
**Wichtig**: So lange wie die generierten Dateien nicht erzeugt wurden,
zeigen die IDE f√ºr diese Klassen und Interfaces entsprechend Fehler an.
Ein √úbersetzen des Projekts oder ein explizites
`./gradlew generateGrammarSource` generiert die fehlenden Dateien und
die Fehlermeldungen sollten verschwinden.

> [!IMPORTANT]
>
> **Hinweis**: Sorgen Sie daf√ºr, dass Ihre IDE tats√§chlich auch die
> **Projekteinstellungen von Gradle √ºbernommen** hat und auch **mit
> Gradle baut**!
>
> 1.  Check, ob die **Projekteinstellungen** in IntelliJ passen:
>
>     1.  Men√º `File > Project Structure > Project Settings > Project`
>         sollte f√ºr Ihr Projekt als SDK ein ‚ÄúJava 25‚Äù zeigen:
>
>         <picture><source media="(prefers-color-scheme: light)" srcset="images/ij-projectsettings-sdk_light.png"><source media="(prefers-color-scheme: dark)" srcset="images/ij-projectsettings-sdk_dark.png"><img src="images/ij-projectsettings-sdk.png"></picture>
>
>     2.  Men√º `File > Project Structure > Project Settings > Libraries`
>         sollte f√ºr Ihr Projekt Jar-Files f√ºr ANTLR4 zeigen:
>
>         <picture><source media="(prefers-color-scheme: light)" srcset="images/ij-projectsettings-libs_light.png"><source media="(prefers-color-scheme: dark)" srcset="images/ij-projectsettings-libs_dark.png"><img src="images/ij-projectsettings-libs.png"></picture>
>
> 2.  Check, ob **IntelliJ mit Gradle baut**:
>
>     Men√º
>     `File > Settings > Build, Execution, Deployment > Build Tools > Gradle`
>     sollte auf Gradle umgestellt sein:
>
>     <picture><source media="(prefers-color-scheme: light)" srcset="images/ij-setting-gradlebuild_light.png"><source media="(prefers-color-scheme: dark)" srcset="images/ij-setting-gradlebuild_dark.png"><img src="images/ij-setting-gradlebuild.png"></picture>
>
>     Unter **‚ÄúBuild & Run‚Äù sollte ‚ÄúGradle‚Äù** ausgew√§hlt sein, die
>     **‚ÄúDistribution‚Äù sollte auf ‚ÄúWrapper‚Äù** stehen, und als **‚ÄúGradle
>     JVM‚Äù** sollte die f√ºr das Projekt verwendete JVM eingestellt sein,
>     d.h. aktuell Java 25.
>
> Siehe auch
> [Compiler-CampusMinden/student-support-code-template](https://github.com/Compiler-CampusMinden/student-support-code-template/blob/master/README.md).

### ‚ÄúHello World‚Äù √ºbersetzen und ausf√ºhren

1.  Grammatik √ºbersetzen und Code generieren: `antlr Hello.g4`
2.  Java-Code kompilieren: `javac *.java`
3.  Lexer ausf√ºhren:
    - `grun Hello start -tokens` (Grammatik ‚ÄúHello‚Äù, Startregel ‚Äústart‚Äù)

    - Alternativ mit kleinem Java-Programm:

      ``` java
      import org.antlr.v4.runtime.*;

      public class Main {
          public static void main(String[] args) throws Exception {
              CharStream input = CharStreams.fromString(IO.readln("?> "));
              Lexer l = new HelloLexer(input);
              Token t = l.nextToken();
              while (t.getType() != Token.EOF) {
                  System.out.println(t);
                  t = l.nextToken();
              }
          }
      }
      ```

### Generierte Dateien und Klassen

Nach dem √úbersetzen finden sich folgende Dateien und Klassen vor:

    .
    |-- bin
    |   |-- HelloBaseListener.class
    |   |-- HelloBaseVisitor.class
    |   |-- HelloLexer.class
    |   |-- HelloListener.class
    |   |-- HelloParser.class
    |   |-- HelloParser$RContext.class
    |   |-- HelloVisitor.class
    |   |-- Main.class
    |-- Hello.g4
    |-- src
        |-- HelloBaseListener.java
        |-- HelloBaseVisitor.java
        |-- HelloLexer.java
        |-- HelloLexer.tokens
        |-- HelloListener.java
        |-- HelloParser.java
        |-- Hello.tokens
        |-- HelloVisitor.java
        |-- Main.java

*Anmerkung*: Die Ordnerstruktur wurde durch ein ANTLR-Plugin f√ºr Eclipse
erzeugt. Bei Ausf√ºhrung in der Konsole liegen alle Dateien in einem
Ordner.

*Anmerkung*: Per Default werden nur die Listener angelegt, f√ºr die
Visitoren muss eine extra Option mitgegeben werden.

Die Dateien `Hello.tokens` und `HelloLexer.tokens` enthalten die Token
samt einer internen Nummer. (Der Inhalt beider Dateien ist identisch.)

Die Datei `HelloLexer.java` enth√§lt den generierten Lexer, der eine
Spezialisierung der abstrakten Basisklasse `Lexer` darstellt. √úber den
Konstruktor wird der zu scannende `CharStream` gesetzt. √úber die Methode
`Lexer#nextToken()` kann man sich die erkannten Token der Reihe nach
zur√ºckgeben lassen. (Diese Methode wird letztlich vom Parser benutzt.)

Die restlichen Dateien werden f√ºr den Parser und verschiedene Arten der
Traversierung des AST generiert (vgl. [AST-basierte
Interpreter](../06-interpretation/astdriven-part1.md)).

### Bedeutung der Ausgabe

Wenn man dem Hello-Lexer die Eingabe

    hello world
    <EOF>

(das `<EOF>` wird durch die Tastenkombination `STRG-D` erreicht) gibt,
dann lautet die Ausgabe

    $ grun Hello start -tokens
    hello world
    <EOF>
    [@0,0:4='hello',<'hello'>,1:0]
    [@1,6:10='world',<GREETING>,1:6]
    [@2,12:11='<EOF>',<EOF>,2:0]

Die erkannten Token werden jeweils auf einer eigenen Zeile ausgegeben.

- `@0`: Das erste Token (fortlaufend nummeriert, beginnend mit 0)
- `0:4`: Das Token umfasst die Zeichen 0 bis 4 im Eingabestrom
- `='hello'`: Das gefundene Lexem (Wert des Tokens)
- `<'hello'>`: Das Token (Name/Typ des Tokens)
- `1:0`: Das Token wurde in Zeile 1 gefunden (Start der Nummerierung mit
  Zeile 1), und startet in dieser Zeile an Position 0

Entsprechend bekommt man mit

    $ grun Hello start -tokens
    hello
      world

    <EOF>
    [@0,0:4='hello',<'hello'>,1:0]
    [@1,8:12='world',<GREETING>,2:2]
    [@2,15:14='<EOF>',<EOF>,4:0]

### ANTLR-Grammatik f√ºr die Lexer-Generierung

- Start der Grammatik mit dem Namen ‚Äú`XYZ`‚Äù mit

      grammar XYZ;

  oder (nur Lexer)

      lexer grammar XYZ;

- Token und Lexer-Regeln starten mit *gro√üen Anfangsbuchstaben*
  (Ausblick: Parser-Regeln starten mit kleinen Anfangsbuchstaben)

  Format: `TokenName : Alternative1 | ... | AlternativeN ;`

  Rekursive Lexer-Regeln sind erlaubt. **Achtung**: Es d√ºrfen keine
  *links-rekursiven* Regeln genutzt werden, etwa wie `ID : ID '*' ID ;`
  ‚Ä¶ (Eine genauere Definition und die Transformation in
  nicht-linksrekursive Regeln siehe [CFG](../02-parsing/cfg.md)).

- Alle Literale werden in *einfache* Anf√ºhrungszeichen eingeschlossen
  (es erfolgt keine Unterscheidung zwischen einzelnen Zeichen und
  Strings wie in anderen Sprachen)

- Zeichenmengen: `[a-z\n]` umfasst alle Zeichen von `'a'` bis `'z'`
  sowie `'\n'`

  `'a'..'z'` ist identisch zu `[a-z]`

- Schl√ºsselw√∂rter: Die folgenden Strings stellen reservierte
  Schl√ºsselw√∂rter dar und d√ºrfen nicht als Token, Regel oder Label
  genutzt werden:

      import, fragment, lexer, parser, grammar, returns, locals, throws, catch, finally, mode, options, tokens

  *Anmerkung*: `rule` ist zwar kein Schl√ºsselwort, wird aber als
  Methodenname bei der Codegenerierung verwendet. =\> Wie ein
  Schl√ºsselwort behandeln!

(vgl.
[github.com/antlr/antlr4/blob/master/doc/lexicon.md](https://github.com/antlr/antlr4/blob/master/doc/lexicon.md))

### Greedy und Non-greedy Lexer-Regeln

Die regul√§ren Ausdr√ºcke `(...)?`, `(...)*` und `(...)+` sind *greedy*
und versuchen soviel Input wie m√∂glich zu matchen.

Falls dies nicht sinnvoll sein sollte, kann man mit einem weiteren `?`
das Verhalten auf *non-greedy* umschalten. Allerdings k√∂nnen non-greedy
Regeln das Verhalten des Lexers u.U. schwer vorhersehbar machen!

Die Empfehlung ist, non-greedy Lexer-Regeln nur sparsam einzusetzen
(vgl.
[github.com/antlr/antlr4/blob/master/doc/wildcard.md](https://github.com/antlr/antlr4/blob/master/doc/wildcard.md)).

## Verhalten des Lexers

### 1. L√§ngster Match

Prim√§res Ziel: Erkennen der l√§ngsten Zeichenkette

``` antlr
CHARS   : [a-z]+ ;
DIGITS  : [0-9]+ ;
FOO     : [a-z]+ [0-9]+ ;
```

Die Regel, die den l√§ngsten Match f√ºr die aktuelle Eingabesequenz
produziert, ‚Äúgewinnt‚Äù.

Im Beispiel w√ºrde ein ‚Äúfoo42‚Äù als `FOO` erkannt und nicht als
`CHARS DIGITS`.

### 2. Reihenfolge

Reihenfolge in Grammatik definiert Priorit√§t

``` antlr
FOO     : 'f' .*? 'r' ;
BAR     : 'foo' .*? 'bar' ;
```

Falls mehr als eine Lexer-Regel die selbe Inputsequenz matcht, dann hat
die in der Grammatik zuerst genannte Regel Priorit√§t.

Im Beispiel w√ºrden f√ºr die Eingabe ‚Äúfoo42bar‚Äù beide Regeln den selben
l√§ngsten Match liefern - die Regel `FOO` ist in der Grammatik fr√ºher
definiert und ‚Äúgewinnt‚Äù.

### 3. Non-greedy Regeln

Non-greedy Regeln versuchen *so wenig* Zeichen wie m√∂glich zu matchen

``` antlr
FOO     : 'foo' .*? 'bar' ;
BAR     : 'bar' ;
```

Hier w√ºrde ein ‚Äúfoo42barbar‚Äù zu `FOO` gefolgt von `BAR` erkannt werden.

Achtung: Nach dem Abarbeiten einer non-greedy Sub-Regel in einer
Lexer-Regel gilt ‚Äú*first match wins*‚Äù

`.*? ('4' | '42')`

=\> Der Teil `'42'` auf der rechten Seite ist ‚Äútoter Code‚Äù (wegen der
non-greedy Sub-Regel `.*?`)!

Die Eingabe ‚Äúx4‚Äù w√ºrde korrekt erkannt, w√§hrende ‚Äúx42‚Äù nur als ‚Äúx4‚Äù
erkannt wird und f√ºr die verbleibende ‚Äú2‚Äù w√ºrde ein *token recognition
error* geworfen.

(vgl.
[github.com/antlr/antlr4/blob/master/doc/wildcard.md](https://github.com/antlr/antlr4/blob/master/doc/wildcard.md))

## Attribute und Aktionen

``` antlr
grammar Demo;

@header {
import java.util.*;
}

@members {
String s = "";
}

start   : TYPE ID '=' INT ';' ;

TYPE    : ('int' | 'float') {s = getText();} ;
INT     : [0-9]+            {System.out.println(s+":"+Integer.valueOf(getText()));};
ID      : [a-z]+            {setText(String.valueOf(getText().charAt(0)));} ;
WS      : [ \t\n]+ -> skip ;
```

### Attribute bei Token (Auswahl)

Token haben Attribute, die man abfragen kann. Dies umfasst u.a. folgende
Felder:

- `text`: Das gefundene Lexem als String
- `type`: Der Token-Typ als Integer
- `index`: Das wievielte Token (als Integer)

(vgl.
[github.com/antlr/antlr4/blob/master/doc/actions.md](https://github.com/antlr/antlr4/blob/master/doc/actions.md))

Zur Auswertung in den Lexer-Regeln muss man anders vorgehen als in
Parser-Regeln: Nach der Erstellung eines Tokens kann man die zum
Attribut geh√∂renden `getX()` und `setX()`-Methoden aufrufen, um die
Werte abzufragen oder zu √§ndern.

Dies passiert im obigen Beispiel f√ºr das Attribut `text`: Abfrage mit
`getText()`, √Ñndern/Setzen mit `setText()`.

Die Methodenaufrufe wirken sich immer auf das gerade erstellte Token
aus.

*Achtung*: Bei Aktionen in Parser-Regeln gelten andere Spielregeln!

### Aktionen mit den Lexer-Regeln

Aktionen f√ºr Lexer-Regeln sind Code-Bl√∂cke in der Zielsprache,
eingeschlossen in geschweifte Klammern. Die Code-Bl√∂cke werden direkt in
die generierten Lexer-Methoden kopiert.

Zus√§tzlich:

- `@header`: Package-Deklarationen und/oder Importe (wird vor der
  Klassendefinition eingef√ºgt)
- `@members`: zus√§tzliche Attribute f√ºr die generierten Lexer- (und
  Parser-) Klassen.

Mit `@lexer::header` bzw. `@lexer::members` werden diese Codebl√∂cke nur
in den generierten Lexer eingef√ºgt.

*Anmerkung*: Lexer-Aktionen m√ºssen am Ende der √§u√üersten Alternative
erscheinen. Wenn eine Lexer-Regel mehr als eine Alternative hat, m√ºssen
diese in runde Klammern eingeschlossen werden.

(vgl.
[github.com/antlr/antlr4/blob/master/doc/grammars.md](https://github.com/antlr/antlr4/blob/master/doc/grammars.md))

## Wrap-Up

Lexer mit ANTLR generieren: Lexer-Regeln werden mit **Gro√übuchstaben**
geschrieben

- L√§ngster Match gewinnt, Gleichstand: zuerst definierte Regel
- *non greedy*-Regeln: versuche so *wenig* Zeichen zu matchen wie
  m√∂glich
- Aktionen beim Matchen

## üìñ Zum Nachlesen

- Parr ([2014](#ref-Parr2014))

> [!NOTE]
>
> <details>
>
> <summary><strong>‚úÖ Lernziele</strong></summary>
>
> - k3: Ich kann Lexer-Regeln in ANTLR formulieren und einsetzen
> - k2: Ich kann das Verhalten des Lexers erkl√§ren, insbesondere l√§ngste
>   Matches und der Einfluss der Reihenfolge der Regeln
> - k3: Ich kann Lexer-Aktionen einsetzen
>
> </details>

> [!TIP]
>
> <details>
>
> <summary><strong>üèÖ Challenges</strong></summary>
>
> **Token und Lexer-Regeln mit ANTLR**
>
> Formulieren Sie f√ºr ANTLR Lexer-Regeln, mit denen folgende Token
> erkannt werden:
>
> - White-Space: Leerzeichen, Tabs, Zeilenumbr√ºche
> - Vergleichsoperatoren: `<`, `>`, `<=`, `>=`, `==`, `<>`
> - If: `if`
> - Then: `then`
> - Else: `else`
> - Namen: Ein Buchstabe, gefolgt von beliebig vielen weiteren
>   Buchstaben und/oder Ziffern
> - Numerische Konstanten: Mindestens eine Ziffer, gefolgt von maximal
>   einem Paar bestehend aus einem Punkt und mindestens einer Ziffer,
>   gefolgt von maximal einem Paar bestehend aus dem Buchstaben ‚ÄúE‚Äù
>   gefolgt von einem ‚Äú+‚Äù oder ‚Äú-‚Äù und mindestens einer Ziffer.
>
> Formulieren Sie Hilfskonstrukte zur Verwendung in mehreren
> Lexer-Regeln als ANTLR-Fragmente.
>
> White-Spaces sollen entfernt werden und nicht als Token weitergereicht
> werden.
>
> **Real-World-Lexer mit ANTLR: Programmiersprache Lox**
>
> Betrachten Sie folgenden Code-Schnipsel in der Sprache
> [‚ÄúLox‚Äù](https://www.craftinginterpreters.com/the-lox-language.html):
>
>     fun fib(x) {
>         if (x == 0) {
>             return 0;
>         } else {
>             if (x == 1) {
>                 return 1;
>             } else {
>                 fib(x - 1) + fib(x - 2);
>             }
>         }
>     }
>
>     var wuppie = fib(4);
>
> Erstellen Sie f√ºr diese fiktive Sprache einen Lexer mit ANTLR. Die
> genauere Sprachdefinition finden Sie unter
> [craftinginterpreters.com/the-lox-language.html](https://www.craftinginterpreters.com/the-lox-language.html).
>
> **Pig-Latin mit ANTLR-Lexer**
>
> Schreiben Sie eine Lexer-Grammatik mit eingebetteten Aktionen f√ºr
> ANTLR sowie ein passendes Programm zur Einbindung des generierten
> Lexers, welches einen Text nach [Pig
> Latin](https://de.wikipedia.org/wiki/Pig_Latin) √ºbersetzt:
>
> - Ist der erste Buchstabe eines Wortes ein Konsonant, schiebe ihn ans
>   Ende des Wortes und f√ºge ‚Äúay‚Äù an.
> - Ist der erste Buchstabe eines Wortes ein Vokal, h√§nge an das Wort
>   ein ‚Äúay‚Äù an.
>
> **Lexing mit ANTLR**
>
> In einem Telefonbuch sind zeilenweise Namen und Telefonnummern
> gespeichert.
>
> Definieren Sie eine Lexer-Grammatik f√ºr ANTLR, mit der Sie die Zeilen
> einlesen k√∂nnen. K√∂nnen Sie dabei verschiedene Formate der
> Telefonnummern ber√ºcksichtigen?
>
>     Heinz 030 5346 983
>     Kalle +49 30 1234 567
>     Lina +49.571.8385-255
>     Rosi (0571) 8385-268
>
> K√∂nnen Sie die Grammatik so anpassen, dass Sie nur m√∂glichst wenige
> verschiedene Token an den Parser weitergeben?
>
> Erg√§nzen Sie Ihre Grammatik um Lexer-Aktionen, so dass Sie die Zeilen,
> die Zeichen (in den Namen) und die Ziffern (in den Telefonnummern)
> z√§hlen k√∂nnen.
>
> **Lexing mit ANTLR**
>
> IBAN f√ºr Deutschland bestehen aus dem K√ºrzel ‚ÄúDE‚Äù sowie einer
> zweistelligen Checksumme, gefolgt von 2x 4 Ziffern f√ºr die Bank
> (ehemalige Bankleitzahl) sowie 2x 4 Ziffern f√ºr die ehemalige
> Kontonummer sowie zwei weiteren Ziffern. Typisch sind zwei Formate:
>
> - Menschenlesbares Format: `DEcc bbbb bbbb kkkk kkkk xx`
> - Maschinenlesbares Format: `DEccbbbbbbbbkkkkkkkkxx`
>
> Definieren Sie eine Lexer-Grammatik f√ºr ANTLR, mit der Sie die
> verschiedenen IBAN-Formate f√ºr Deutschland einlesen k√∂nnen.
> </details>

------------------------------------------------------------------------

> [!NOTE]
>
> <details>
>
> <summary><strong>üëÄ Quellen</strong></summary>
>
> <div id="refs" class="references csl-bib-body hanging-indent">
>
> <div id="ref-Parr2014" class="csl-entry">
>
> Parr, T. 2014. *The Definitive ANTLR 4 Reference*. Pragmatic
> Bookshelf.
> <https://learning.oreilly.com/library/view/the-definitive-antlr/9781941222621/>.
>
> </div>
>
> </div>
>
> </details>

------------------------------------------------------------------------

<img src="https://licensebuttons.net/l/by-sa/4.0/88x31.png" width="10%">

Unless otherwise noted, this work is licensed under CC BY-SA 4.0.

<blockquote><p><sup><sub><strong>Last modified:</strong> 5b88ada (homework: remove Java as implementation language, 2025-11-19)<br></sub></sup></p></blockquote>
